{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFaCDlDyV3IbwlGEB4hbBI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EricaAndreose/enoam_doc/blob/main/TEIfy_doc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLLfiPbZ3i3c"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si importano le seguenti librerie:\n",
        "\n",
        "**datetime**: fornisce classi per manipolare date e orari in modo semplice e potente.\n",
        "\n",
        "**BeautifulSoup**: utilizzata per analizzare documenti HTML e XML, permettendo di estrarre informazioni e navigare nella struttura del documento."
      ],
      "metadata": {
        "id": "uL24jslV4NPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FIX AND ALIGN PARAGRAPHS TO TEI\n",
        "def TEIps(soup):\n",
        "    try:\n",
        "        #Find all paragraph tags in the soup object\n",
        "        paragraphs = soup.find_all('p')\n",
        "        for p in paragraphs:\n",
        "            #Set the 'xml:id' attribute to the value of the 'id' attribute\n",
        "            p['xml:id'] = p['id']\n",
        "            #Set the 'n' attribute to the value of the 'data-counter' attribute\n",
        "            p['n'] = p['data-counter']\n",
        "            #Remove the 'id', 'class', 'data-counter' attribute from the paragraph tag\n",
        "            del p['id']\n",
        "            del p['class']\n",
        "            del p['data-counter']\n",
        "    #If an error occurs, do nothing\n",
        "    except: None\n"
      ],
      "metadata": {
        "id": "JSf1G7hH_Px0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`TEIps` ha lo scopo di trasformare i tag `p` di un documento HTML in modo che siano allineati con il formato TEI.\n",
        "\n"
      ],
      "metadata": {
        "id": "VfsYPp5K_d0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FIX AND ALIGN CURATOR NOTES TO TEI\n",
        "def TEIcuratornotes(soup):\n",
        "    try:\n",
        "        #Find the curator notes section in the soup object (ol ordered list and li list item)\n",
        "        curatornotes = soup.find('ol', id='curatorNotes')\n",
        "        notes = curatornotes.find_all('li')\n",
        "        for li in notes:\n",
        "            li.name = 'note' #change the tag name\n",
        "            li['xml:id'] = li['id']\n",
        "            li['corresp'] = li['about']\n",
        "            li['type'] = 'footnote'\n",
        "            del li['id']\n",
        "            del li['about']\n",
        "            del li['typeof']\n",
        "            del li['property']\n",
        "            del li['resource']\n",
        "        #change the tag name from 'ol' to 'noteGrp'\n",
        "        curatornotes.name = 'noteGrp'\n",
        "        curatornotes['xml:id'] = curatornotes['id']\n",
        "        del curatornotes['id']\n",
        "    except: None"
      ],
      "metadata": {
        "id": "c5EoREw_C6ZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Questa funzione ha lo scopo di trasformare una lista ordinata di note del curatore in un gruppo di note conforme al formato TEI."
      ],
      "metadata": {
        "id": "0kIugxKwDwM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FIX AND ALIGN MORO NOTES TO TEI\n",
        "def TEImoronotes(soup):\n",
        "    try:\n",
        "        moronotes = soup.find('ol', id='moroNotes')\n",
        "        notes = moronotes.find_all('li')\n",
        "        for li in notes:\n",
        "            li.name = 'note'\n",
        "            li['xml:id'] = li['id']\n",
        "            li['corresp'] = li['about']\n",
        "            li['type'] = 'footnote'\n",
        "            del li['id']\n",
        "            del li['about']\n",
        "            del li['typeof']\n",
        "            del li['property']\n",
        "            del li['resource']\n",
        "        moronotes.name = 'noteGrp'\n",
        "        moronotes['xml:id'] = moronotes['id']\n",
        "        del moronotes['id']\n",
        "        del moronotes['type']\n",
        "        del moronotes['data-alert']\n",
        "    except: None"
      ],
      "metadata": {
        "id": "vHTK7giJEo5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo stesso processo viene eseguito per le note di Moro."
      ],
      "metadata": {
        "id": "DmEMYLWRFdka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CONVERT <em> INTO <hi rend=\"italics\">\n",
        "def TEIitalics(soup):\n",
        "    try:\n",
        "        italics = soup.find_all('em')\n",
        "        for em in italics:\n",
        "            if len(em.get_text(strip=True)) == 0:\n",
        "                em.decompose()\n",
        "            else:\n",
        "                em.name = 'hi'\n",
        "                em['rend'] = 'italic'\n",
        "    except: None\n"
      ],
      "metadata": {
        "id": "UKqEpjaQE1sS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Qui tutte le enfasi del testo vengono propriamente taggate per il formato TEI con l'attributo 'italics'."
      ],
      "metadata": {
        "id": "nSlTXtMXFiG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CONVERT <a> INTO <ref>\n",
        "def TEIas(soup):\n",
        "    try:\n",
        "        arefs = soup.find_all('a')\n",
        "        for a in arefs:\n",
        "            a.name = 'ref'\n",
        "            if a.has_attr('id'):\n",
        "                a['xml:id'] = a['id']\n",
        "                del a['id']\n",
        "            a['target'] = a['href']\n",
        "            del a['href']\n",
        "    except: None"
      ],
      "metadata": {
        "id": "QvTT3eyCE37a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Qui i link inseriti nel testo con il tag `a href `vengono convertiti in ref per la formattazione TEI."
      ],
      "metadata": {
        "id": "oGwuJl0aFuUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CONVERT <sup> INTO <hi rend=\"sup\">\n",
        "def TEIsups(soup):\n",
        "    try:\n",
        "        sups = soup.find_all('sup')\n",
        "        for sup in sups:\n",
        "            if len(sup.get_text(strip=True)) == 0:\n",
        "                sup.decompose()\n",
        "            else:\n",
        "                sup.name = 'hi'\n",
        "                sup['rend'] = 'sup'\n",
        "    except: None"
      ],
      "metadata": {
        "id": "hqwuzS3uE6CS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La stessa cosa viene fatta per i tag `sup`."
      ],
      "metadata": {
        "id": "LPqYjYYeJkBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CONVERT <strong> INTO <hi rend=\"bold\">\n",
        "def TEIstrongs(soup):\n",
        "    try:\n",
        "        strongs = soup.find_all('strong')\n",
        "        for strong in strongs:\n",
        "            if len(strong.get_text(strip=True)) == 0:\n",
        "                strong.decompose()\n",
        "            else:\n",
        "                strong.name = 'hi'\n",
        "                strong['rend'] = 'bold'\n",
        "    except: None"
      ],
      "metadata": {
        "id": "8SInNjCJE7yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La stessa cosa viene fatta per i tag `bold`."
      ],
      "metadata": {
        "id": "WjMu_aSCLA6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# REMOVE EMPTY TAGS\n",
        "def cleaner_empty(soup):\n",
        "    try:\n",
        "        tags = soup.sourceDesc.find_all()\n",
        "        for tag in tags:\n",
        "            if len(tag.contents) == 0:\n",
        "                tag.decompose()\n",
        "    except: None\n",
        "    return soup.prettify()\n"
      ],
      "metadata": {
        "id": "aGELkEbAE90q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Qui si rimuovono possibili tag senza contenuto che sono rimasti nell'html."
      ],
      "metadata": {
        "id": "2e9pDjZILFmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CONVERT MENTIONED ENTITIES\n",
        "def convert_entities(soup, old_soup, typeof):\n",
        "    #find all elements in old_soup with the attribute 'typeof' matching the given type\n",
        "    category = old_soup.find_all(attrs={'typeof': typeof})\n",
        "    #create a new tag list based on the typeof parameter\n",
        "    if typeof == 'foaf:Person':\n",
        "        lst = soup.new_tag('listPerson')\n",
        "    elif typeof == 'foaf:Organization':\n",
        "        lst = soup.new_tag('listOrg')\n",
        "    elif typeof == 'dcterms:Location':\n",
        "        lst = soup.new_tag('listPlace')\n",
        "    elif typeof == 'fabio:Expression':\n",
        "        lst = soup.new_tag('listBibl')\n",
        "        lst['xml:id'] = 'bibliographic-references'\n",
        "    for entity in category:\n",
        "        # Create new tags based on the typeof parameter\n",
        "        if typeof == 'foaf:Person':\n",
        "            name = soup.new_tag('persName')\n",
        "            tag = soup.new_tag('person')\n",
        "        elif typeof == 'foaf:Organization':\n",
        "            name = soup.new_tag('orgName')\n",
        "            tag = soup.new_tag('org')\n",
        "        elif typeof == 'dcterms:Location':\n",
        "            name = soup.new_tag('placeName')\n",
        "            tag = soup.new_tag('place')\n",
        "        elif typeof == 'fabio:Expression':\n",
        "            tag = soup.new_tag('bibl')\n",
        "\n",
        "        try:\n",
        "            #append the name tag to the main tag\n",
        "            tag.append(name)\n",
        "        except: None\n",
        "\n",
        "        #find all mentions of the entity in soup and metadata in old_soup\n",
        "        mentions = soup.find_all(attrs={'property': 'dcterms:references', 'resource': entity['about']})\n",
        "        metas = old_soup.find_all(attrs={'about': entity['about']})\n",
        "        bibrefs = soup.find_all(attrs={'property': 'biro:references', 'resource': entity['about']})\n",
        "\n",
        "        #process metadata to extract and set attributes\n",
        "        if metas:\n",
        "            for meta in metas:\n",
        "                xmlid = meta['about'].split('/')[-1]\n",
        "                tag['xml:id'] = xmlid\n",
        "                tag['corresp'] = meta['about']\n",
        "                if meta.has_attr('property') and meta['property'] == 'rdfs:label':\n",
        "                    name.string = meta['content']\n",
        "                elif meta.has_attr('property') and meta['property'] == 'owl:sameAs':\n",
        "                    tag['sameAs'] = meta['resource']\n",
        "                elif meta.has_attr('property') and meta['property'] == 'dcterms:bibliographicCitation':\n",
        "                    tag.string = meta['content']\n",
        "\n",
        "        #convert mentions to the corresponding TEI format\n",
        "        if mentions:\n",
        "            for mention in mentions:\n",
        "                if typeof == 'foaf:Person':\n",
        "                    mention.name = 'persName'\n",
        "                elif typeof == 'foaf:Organization':\n",
        "                    mention.name = 'orgName'\n",
        "                elif typeof == 'dcterms:Location':\n",
        "                    mention.name = 'placeName'\n",
        "                mention['ref'] = f'#{tag[\"xml:id\"]}'\n",
        "                del mention['about']\n",
        "                del mention['class']\n",
        "                del mention['id']\n",
        "                del mention['property']\n",
        "                del mention['resource']\n",
        "                del mention['typeof']\n",
        "\n",
        "        #convert bibliographic references to the TEI format\n",
        "        if bibrefs:\n",
        "            for bibref in bibrefs:\n",
        "                bibref.name = 'bibl'\n",
        "                bibref['ref'] = f'#{tag[\"xml:id\"]}'\n",
        "                del bibref['about']\n",
        "                del bibref['class']\n",
        "                del bibref['id']\n",
        "                del bibref['property']\n",
        "                del bibref['resource']\n",
        "                del bibref['typeof']\n",
        "\n",
        "        #append the tag to the list\n",
        "        lst.append(tag)\n",
        "\n",
        "    #append the list to the source description section of the TEI document\n",
        "    soup.sourceDesc.append(lst)"
      ],
      "metadata": {
        "id": "VPD6fVxcE_b6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# INSERT METADATA\n",
        "def add_metadata(soup, old_soup, metadata):\n",
        "\n",
        "    # TITLE\n",
        "    title = metadata['title']\n",
        "    soup.title.insert(0, title)\n",
        "\n",
        "\n",
        "    # AUTHOR\n",
        "    author = metadata['author']\n",
        "    soup.author.insert(0, author)\n",
        "\n",
        "\n",
        "    # CURATOR\n",
        "    curator = metadata['curator']\n",
        "    soup.principal.insert(0, curator)\n",
        "\n",
        "\n",
        "    # IDENTIFIER\n",
        "    identifier = old_soup.find(attrs={'name': 'dcterms.identifier'})\n",
        "    soup.idno.insert(0, identifier['content'])\n",
        "\n",
        "\n",
        "    # ABSTRACT\n",
        "    abstract = metadata['abstract']\n",
        "    soup.abstract.insert(0, abstract)\n",
        "\n",
        "\n",
        "    # STATUS\n",
        "    status = metadata['docstatus']\n",
        "    soup.revisionDesc['status'] += status\n",
        "    change = soup.new_tag('change')\n",
        "    change.string = f'{datetime.now().strftime(\"%Y-%m-%d\")}'\n",
        "    soup.revisionDesc.insert(0, change)\n",
        "\n",
        "\n",
        "    # DOCUMENT TYPE, DOCUMENT SUBJECT, AUTHOR ROLE\n",
        "    catrefs = soup.find_all('catRef')\n",
        "    for catref in catrefs:\n",
        "        if catref.has_attr('scheme') and catref['scheme'] == 'https://www.w3id.org/moro/voc/types/':\n",
        "            for doctype in metadata['doctypeList']:\n",
        "                catref['target'] += 'https://www.w3id.org/moro/voc/types/' + doctype.replace('.', '')[3:] + ' '\n",
        "        elif catref.has_attr('scheme') and catref['scheme'] == 'https://www.w3id.org/moro/voc/subjects/':\n",
        "            for subject in metadata['doctopicList']:\n",
        "                catref['target'] += 'https://www.w3id.org/moro/voc/subjects/' + subject.replace('doctopic.', 'subject') + ' '\n",
        "        elif catref.has_attr('scheme') and catref['scheme'] == 'https://www.w3id.org/moro/voc/roles/':\n",
        "            for role in metadata['roleList']:\n",
        "                catref['target'] += 'https://www.w3id.org/moro/voc/roles/' + role.replace('.', '') + ' '\n",
        "        catref['target'] = catref['target'][:-1]"
      ],
      "metadata": {
        "id": "FKeqvXUEFB86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PROVENANCE\n",
        "    try:\n",
        "        for prov in metadata['provenance']:\n",
        "            bibl = soup.new_tag('bibl')\n",
        "            bibl.string = prov\n",
        "            soup.sourceDesc.listBibl.append(bibl)\n",
        "    except: None"
      ],
      "metadata": {
        "id": "7mnYR_oRFFFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DATE AND SPATIAL COVERAGE\n",
        "    try:\n",
        "        if metadata['eventPlace'] or metadata['eventDate']:\n",
        "            xenodata = soup.new_tag('xenoData')\n",
        "\n",
        "            if metadata['eventPlace']:\n",
        "                eventplace = metadata['eventPlace']\n",
        "                coverage = soup.new_tag('dcterms:spatial')\n",
        "                coverage.string = eventplace\n",
        "                xenodata.append(coverage)\n",
        "\n",
        "            if metadata['eventDate']:\n",
        "                eventdate = metadata['eventDate']\n",
        "\n",
        "                if '-' in eventdate:\n",
        "                    if eventdate.endswith('--'):\n",
        "                        eventdate = eventdate[:-2]\n",
        "                    elif eventdate.endswith('-'):\n",
        "                        eventdate = eventdate[:-1]\n",
        "                    split_eventdate = eventdate.split('-')\n",
        "                    new_split_date = []\n",
        "                    for t in split_eventdate:\n",
        "                        if len(t) == 1:\n",
        "                            t = '0' + t\n",
        "                        new_split_date.append(t)\n",
        "                    eventdate = '-'.join(new_split_date)\n",
        "\n",
        "                coverage = soup.new_tag('dcterms:date')\n",
        "                coverage.string = eventdate\n",
        "                xenodata.append(coverage)\n",
        "            soup.teiHeader.append(xenodata)\n",
        "    except: None"
      ],
      "metadata": {
        "id": "C9TW-_BUFGyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CONVERT QUOTES\n",
        "def convert_quotes(soup):\n",
        "    quotes = soup.find_all(attrs={'typeof': 'doco:TextChunk'})\n",
        "    for quote in quotes:\n",
        "        quote.name = 'quote'\n",
        "        del quote['about']\n",
        "        del quote['class']\n",
        "        del quote['id']\n",
        "        del quote['typeof']"
      ],
      "metadata": {
        "id": "jWCvUpdFFIri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MAIN FUNCTION FOR CONVERTING HTML INTO TEI-XML\n",
        "def teify(html_path, metadata):\n",
        "\n",
        "    # OPEN FILE AND CREATE SOUP\n",
        "    with open(html_path, encoding='utf-8') as fp:\n",
        "        old_soup = BeautifulSoup(fp, 'html.parser')\n",
        "        fp.close()\n",
        "\n",
        "\n",
        "    # CREATE NEW TEI SOUP\n",
        "    tei = '<?xml version=\"1.0\" encoding=\"UTF-8\"?><TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns:dcterms=\"http://purl.org/dc/terms/\"><teiHeader><fileDesc><titleStmt><title></title><author></author><principal></principal></titleStmt><publicationStmt><publisher>Università di Bologna</publisher><pubPlace>Bologna</pubPlace><date>2021</date><idno type=\"DOI\"></idno><availability><licence target=\"http://creativecommons.org/licenses/by-nc/4.0/\">Creative Commons Attribuzione - Non commerciale 4.0 Internazionale</licence></availability></publicationStmt><sourceDesc><listBibl xml:id=\"sources\"></listBibl></sourceDesc></fileDesc><encodingDesc><projectDesc>Il documento è stato annotato per essere indicizzato all\\'interno dell\\'Edizione Nazionale delle Opere di Aldo Moro.</projectDesc><editorialDecl><correction status=\"high\" method=\"silent\">Gli unici interventi redazionali, peraltro marginali, sono eseguiti per correggere evidenti refusi nel processo di stampa, le sviste banali, le omissioni di punteggiatura e piccole, lapalissiane correzioni e integrazioni a lacune di testo che si rendono necessarie. Quando indispensabile, una preposizione o una congiunzione mancante si inserisce tra parentesi quadre. Gli ulteriori interventi nel testo vanno segnalati con il segno grafico convenzionale delle parentesi quadre, applicato raramente anche alla punteggiatura, solamente quando rischia di compromettere la corretta comprensione del testo. In tutti gli altri casi, occorre segnalare ugualmente con il segno grafico consueto del «sic» tra parentesi quadre, per evocare un intervento dei curatori.</correction><normalization>Si modificano gli accenti gravi, che sono stati resi in acuti, anche perché corrispondono ai limiti degli impianti tipografici utilizzati all’epoca.</normalization></editorialDecl></encodingDesc><profileDesc><abstract></abstract><textClass><catRef scheme=\"https://www.w3id.org/moro/voc/types/\" target=\"\"/><catRef scheme=\"https://www.w3id.org/moro/voc/subjects/\" target=\"\"/><catRef scheme=\"https://www.w3id.org/moro/voc/roles/\" target=\"\"/></textClass></profileDesc><revisionDesc status=\"\"></revisionDesc></teiHeader><text><body><head></head></body></text></TEI>'\n",
        "    soup = BeautifulSoup(tei, 'xml')\n",
        "\n",
        "\n",
        "    # INSERT METADATA IN TEI SOUP\n",
        "    add_metadata(soup, old_soup, metadata)\n",
        "\n",
        "\n",
        "    # POPULATE NEW BODY\n",
        "    if old_soup.find('body'):\n",
        "        soup.body.insert(1, old_soup.body)\n",
        "        soup.body.body.unwrap()\n",
        "\n",
        "\n",
        "    # CONVERT <h1>, <h2>, ... INTO <head>\n",
        "    h1 = soup.find('h1')\n",
        "    h2 = soup.find_all('h2')\n",
        "    if h1:\n",
        "        soup.head.string = soup.h1.get_text(strip=True)\n",
        "        soup.h1.decompose()\n",
        "    if h2:\n",
        "        for h in h2:\n",
        "            h.name = 'head'\n",
        "\n",
        "\n",
        "    # LAUNCH OTHER FUNCTIONS\n",
        "    convert_entities(soup, old_soup, 'foaf:Person')\n",
        "    convert_entities(soup, old_soup, 'foaf:Organization')\n",
        "    convert_entities(soup, old_soup, 'dcterms:Location')\n",
        "    convert_entities(soup, old_soup, 'fabio:Expression')\n",
        "    convert_quotes(soup)\n",
        "    TEIps(soup)\n",
        "    TEIitalics(soup)\n",
        "    TEIstrongs(soup)\n",
        "    TEIas(soup)\n",
        "    TEIsups(soup)\n",
        "    TEIcuratornotes(soup)\n",
        "    TEImoronotes(soup)\n",
        "    cleaner_empty(soup)\n",
        "\n",
        "\n",
        "    # RETURN TEI AS STRING\n",
        "    return str(soup)"
      ],
      "metadata": {
        "id": "TKG1OKJwFKFi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}