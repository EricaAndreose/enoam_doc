{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPWhv2s3hWMteWOUnQksrnP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EricaAndreose/enoam_doc/blob/main/Recast_doc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hO3b_gLb2eDu"
      },
      "outputs": [],
      "source": [
        "import re, unicodedata, unidecode\n",
        "from bs4 import BeautifulSoup\n",
        "from qwikidata.entity import WikidataItem\n",
        "from qwikidata.linked_data_interface import get_entity_dict_from_api"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Qui stiamo importando le seguenti librerie:\n",
        "\n",
        "\n",
        "*   **re**: Per lavorare con le espressioni regolari.\n",
        "*   **unicodedata**: Per lavorare con i dati Unicode.\n",
        "*   **unidecode**: Per traslitterare i caratteri Unicode in caratteri ASCII.\n",
        "*   **BeautifulSoup**: Per analizzare e fare parsing di documenti HTML.\n",
        "*   **WikidataItem**: Per interagire con gli elementi di Wikidata.\n",
        "*   **get_entity_dict_from_api**: Per ottenere i dati di un'entità da Wikidata tramite l'API."
      ],
      "metadata": {
        "id": "m_ucdIeV2j9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CONVERT FAKE HEAD AND BODY INTO ACTUAL TAGS\n",
        "def convert_head_body(old_soup, soup):  # it takes in input two BeautifulSoup objects\n",
        "    headfile = old_soup.find('div', id='headFile') # searching for \"div\" elements with \"headFile\" as id\n",
        "    bodyfile = old_soup.find('div', id='bodyFile') # searching for \"div\" elements with \"bodyFile\" as id\n",
        "    if headfile:\n",
        "        soup.head.insert(1, headfile) # Insert headfile into soup's head tag\n",
        "        headfile.unwrap() # Remove headfile from its original position\n",
        "    if bodyfile:\n",
        "        soup.body.insert(1, bodyfile) # Insert bodyfile into soup's body tag\n",
        "        bodyfile.unwrap() # Remove bodyfile from its original position"
      ],
      "metadata": {
        "id": "EsvmPQ0T2-91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La funzione `convert_head_body` prende due oggetti BeautifulSoup come input: `old_soup` e `soup`.\n",
        "\n",
        "Cerca all'interno di `old_soup` due elementi div con gli id \"headFile\" e \"bodyFile\". Se questi elementi vengono trovati, vengono inseriti rispettivamente all'interno dei tag `head` e `body` di `soup`, e poi vengono rimossi dalla loro posizione originale in `old_soup` usando il metodo `unwrap()`.\n",
        "\n",
        "In pratica, questa funzione sposta il contenuto dei `div` \"headFile\" e \"bodyFile\" da `old_soup` ai tag `head` e `body` di `soup`, aggiornando la struttura del documento HTML.\n",
        "\n",
        "❓ Dove prende tutte queste cose di input? Vai a vedere su main.py quando lanci \"r\" per recast."
      ],
      "metadata": {
        "id": "Oe-bRQD94oSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# INSERT META TAGS\n",
        "def insert_seo_meta(soup, metadata): # takes in input the refined BS object and the metadata from MongoDB database\n",
        "    split_ident = metadata['ident'].split('_') # split the 'ident' field of the metadata stored for every object in MongoDB (ex. 2_2_0_001)\n",
        "\n",
        "    section = '' # create empty string variables\n",
        "    volume = ''\n",
        "    curators = ''\n",
        "    if split_ident[0] == '1':\n",
        "        section = 'Scritti e Discorsi'\n",
        "        if split_ident[1] == '1':\n",
        "            volume = 'Gli anni giovanili (1932-1946)'\n",
        "            curators = 'Gaetano Crociata e Paolo Trionfini'\n",
        "        elif split_ident[1] == '2':\n",
        "            volume = 'Il periodo dossettiano e di Iniziativa democratica (1946-1958)'\n",
        "            if split_ident[2] == '1':\n",
        "                volume = 'Il periodo dossettiano (1946-1951)'\n",
        "            elif split_ident[2] == '2':\n",
        "                volume = 'Iniziativa democratica (1952-1958)'\n",
        "            curators = 'Ugo De Siervo e Enrico Galavotti'\n",
        "        elif split_ident[1] == '3':\n",
        "            volume = 'Il centro-sinistra (1952-1958)'\n",
        "            if split_ident[2] == '1':\n",
        "                volume = 'Segretario della DC (1959-1963)'\n",
        "            elif split_ident[2] == '2':\n",
        "                volume = 'La prima legislatura di centro-sinistra (1964-1968)'\n",
        "            curators = 'Leopoldo Nuti e Paolo Pombeni'\n",
        "        elif split_ident[1] == '4':\n",
        "            volume = 'L’ultima fase (1969-1978)'\n",
        "            if split_ident[2] == '1':\n",
        "                volume = 'Al ministero degli Esteri e all’opposizione nel partito (giugno 1968 – maggio 1973)'\n",
        "            elif split_ident[2] == '2':\n",
        "                volume = 'Il ritorno al centro-sinistra e la “solidarietà nazionale” (giugno 1973 – maggio 1978)'\n",
        "            curators = 'Guido Formigoni e Agostino Giovagnoli'\n",
        "    elif split_ident[0] == '2':\n",
        "        section = 'Opere Giuridiche'\n",
        "        if split_ident[1] == '1':\n",
        "            volume = 'Le prime monografie (1939-1942)'\n",
        "            curators = 'Luciano Eusebi'\n",
        "        elif split_ident[1] == '2':\n",
        "            volume = 'Le dispense di filosofia del diritto (1941-1947)'\n",
        "            curators = 'Nicola Antonetti e Renato Moro'\n",
        "        elif split_ident[1] == '3':\n",
        "            volume = 'Le monografie del dopoguerra (1947-1951)'\n",
        "            curators = 'Marco Pelissero'\n",
        "        elif split_ident[1] == '4':\n",
        "            volume = 'Le lezioni di istituzioni di diritto e procedura penale'\n",
        "            curators = 'Marco Pelissero'"
      ],
      "metadata": {
        "id": "ybLVaj9x5R8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La funzione `insert_seo_meta` prende in input un oggetto BeautifulSoup (`soup`) e i metadati (`metadata`) di un documento. Lo scopo di questa funzione è quello di inserire meta tag nel documento HTML rappresentato da soup basandosi sui metadati forniti da MongoDB.\n",
        "\n",
        "Inizialmente, l'identificativo del documento (`ident`) viene estratto dai metadati di MongoDB e suddiviso in parti (viene splittato). Queste parti vengono poi utilizzate per determinare la sezione, il volume e i curatori del documento.\n",
        "\n",
        "La funzione crea nuovi tag meta per la sezione, il volume e i curatori, impostando il loro contenuto in base ai valori determinati in precedenza. Questi tag meta vengono quindi aggiunti all'head del documento HTML.\n",
        "\n",
        "Qui è importante controllare la correttezza dei dati inseriti nel codice (sono già state fatte alcune modifiche in corso d'opera per la correzione di alcuni nomi di ricercatori). Nel caso di introduzione di nuovi sezioni/volumi nell'edizione digitale, vanno aggiunti qui.\n",
        "\n",
        "Ciò che ci crea qui verrà visualizzato concretamente nel sito nella pagina del singolo documento nella sezione \"metadati\" e \"citazione bibliografica\".\n"
      ],
      "metadata": {
        "id": "sLCYxSImoMFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    description = soup.new_tag('meta') #create variable with new meta tag\n",
        "    description['name'] = 'description' #create attribute name\n",
        "    description['content'] = f\"Edizione Nazionale delle Opere di Aldo Moro, {section}, {volume}, 2024\" #create content of the meta tag taking the volum section infos from the variables from before\n",
        "\n",
        "    rights = soup.new_tag('meta')\n",
        "    rights['name'] = 'dcterms.rights'\n",
        "    rights['content'] = 'https://creativecommons.org/licenses/by-nc/4.0'\n",
        "\n",
        "    doi = soup.new_tag('meta')\n",
        "    doi['name'] = 'dcterms.identifier'\n",
        "    doi['content'] = f\"10.48678/unibo/aldomoro{'.'.join(split_ident)}\"\n",
        "\n",
        "    url = soup.new_tag('meta')\n",
        "    url['name'] = 'dcterms.relation'\n",
        "    url['content'] = f\"https://doi.org/{doi['content']}\"\n",
        "\n",
        "    citation = soup.new_tag('meta')\n",
        "    citation['name'] = 'dcterms.bibliographicCitation'\n",
        "    citation['content'] = f\"Moro, Aldo, {metadata['title']}, in Aldo Moro, Edizione Nazionale delle Opere di Aldo Moro, Sezione {split_ident[0]}, {section}, Vol. {split_ident[1]}, {volume}, a cura di {curators}, edizione e nota storico-critica di {metadata['curator']}, Bologna, Università di Bologna, 2024. DOI: https://doi.org/10.48678/unibo/aldomoro{'.'.join(split_ident)}.\"\n",
        "\n",
        "    viewport = soup.new_tag('meta')\n",
        "    viewport['name'] = 'viewport'\n",
        "    viewport['content'] = 'width=device-width, initial -scale=1.0'\n",
        "    charset = soup.new_tag('meta')\n",
        "    charset['charset'] = 'utf-8'\n",
        "\n",
        "    soup.head.insert(0, description) #insert the new tags in the head section of the html\n",
        "    soup.head.insert(0, citation)\n",
        "    soup.head.insert(0, doi)\n",
        "    soup.head.insert(0, url)\n",
        "    soup.head.insert(0, rights)\n",
        "    soup.head.insert(0, viewport)\n",
        "    soup.head.insert(0, charset)\n"
      ],
      "metadata": {
        "id": "sXRDEXIjp6gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Qui si creano e si inseriscono i meta tag nell'html finale.\n",
        "\n",
        "`soup.new_tag('meta')`: Crea un nuovo tag meta e lo assegna alla variabile desiderata (description, rights, doi etc.).\n",
        "\n",
        "Viene poi impostato l'attributo `name` e il `content` del tag.\n",
        "\n",
        "Fai attenzione specialmente alla *bibliographic citation*, qui abbiamo cambiato l'anno per allinearci con il periodo in cui abbiamo generato i nuovi documenti caricati nell'edizione.\n"
      ],
      "metadata": {
        "id": "YnprqXPFqoDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# REMOVE EMPTY TAGS INSIDE HEAD\n",
        "def clean_empty_head(soup):\n",
        "    tags = soup.head.find_all('div') #find all div tag in the head and store them in the tags variable\n",
        "    for tag in tags: #iterate through the tags variable\n",
        "        if not tag.find('meta'): #if the tag does not contain a meta tag\n",
        "            tag.decompose() #remove the tag from the document\n",
        "\n",
        "\n",
        "# REMOVE EMPTY TAGS INSIDE BODY\n",
        "def clean_empty_body(soup):\n",
        "    tags = soup.body.find_all() #find all tags in the body and store them in the tags variable\n",
        "    for tag in tags:\n",
        "        if len(tag.get_text(strip=True)) == 0: #if the tag is empty\n",
        "            tag.decompose() #remove the tag from the document\n",
        "        elif tag.has_attr('class') and tag['class'] == 'no-abstract': #if the tag has the class 'no-abstract'\n",
        "            tag.unwrap()  #remove the tag from the document\n"
      ],
      "metadata": {
        "id": "X9rPZjUbCugs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Qui si puliscono il tag `head` e il tag `body` del documento HTML rimuovendo tutti i tag `div` vuoti, (ovvero quelli che non contengono tag `meta`) e nel body quelli con la classe `no-abstract`."
      ],
      "metadata": {
        "id": "Zeyu1IwgM9Od"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FIX TITLE AND REMOVE TAGS INSIDE IT\n",
        "def clean_title(soup, spans, metadata):\n",
        "    title = soup.new_tag('title') #create new variable title\n",
        "\n",
        "    # THEIR DOCUMENTS ARE EXCEPTIONS!!!\n",
        "    if metadata['curator'] != 'Caterina Iagnemma' and metadata['curator'] != 'Sofia Confalonieri' and metadata['curator'] != 'Maurizio Cau': #if the curator IS NOT Iagnemma, Confalonieri or Cau\n",
        "\n",
        "        h3 = soup.find('h3')\n",
        "        h2 = soup.find('h2')\n",
        "        h1 = soup.find('h1')\n",
        "        text = False\n",
        "        if h3:\n",
        "            h3.name = 'h1' #h3 became h1\n",
        "            for span in spans: #iterate through the spans list\n",
        "                if span in h3: #if the span is inside h3\n",
        "                    span.unwrap() #remove the span from the document\n",
        "            text = h3.get_text(strip=True) #extract the text of h2 and assign it to the variable \"text\" removing starting and closing empty space\n",
        "        elif h2:\n",
        "            h2.name = 'h1'\n",
        "            for span in spans:\n",
        "                if span in h2:\n",
        "                    span.unwrap()\n",
        "            text = h2.get_text(strip=True)\n",
        "        elif h1:\n",
        "            for span in spans:\n",
        "                if span in h1:\n",
        "                    span.unwrap()\n",
        "            text = h1.get_text(strip=True)\n",
        "        else: #if there aren't h3, h2 or h1\n",
        "            p = soup.find('p') #find the p tag\n",
        "            if p:\n",
        "                strong = p.find('strong') #find the strong tag inside the p tag\n",
        "                if strong:\n",
        "                    strong.unwrap() #remove the strong tag from the document\n",
        "                p.name = 'h1' #p became h1\n",
        "                for span in spans: #iterate through the spans list\n",
        "                    if span in p:\n",
        "                        span.unwrap() #remove the span from the document\n",
        "                text = p.get_text(strip=True) #extract the text of p and assign it to the variable \"text\" removing starting and closing empty space\n",
        "        if text: #if text is not empty\n",
        "            title.append(text) #append the text to the title variable\n",
        "\n",
        "    else: #if the curator IS Iagnemma, Confalonieri or Cau\n",
        "        h1 = soup.find('h1') #find the h1 tag\n",
        "        title.append(h1.get_text(strip=True)) #extract the text of h1 and assign it to the variable \"title\" removing starting and closing empty space\n",
        "    soup.head.insert(0, title)  #insert the title in the head of the document"
      ],
      "metadata": {
        "id": "NfcO5WTSN8i8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In questa parte si va a prelevare e pulire il testo del titolo del documento.\n",
        "La funzione Crea un nuovo tag `title` da aggiungere all'head del documento HTML.\n",
        "Poi controlla il valore del curatore nel dizionario metadata.\n",
        "\n",
        "Se il curatore non è uno tra Caterina Iagnemma, Sofia Confalonieri o Maurizio Cau:\n",
        "\n",
        "Cerca i tag `h3`, `h2`, e `h1` nel documento HTML.\n",
        "Se ne trova uno, lo trasforma in `h1` e rimuove eventuali tag `span` contenuti al suo interno, quindi estrae il testo dal tag e lo salva nella variabile `text`.\n",
        "\n",
        "Se non trova nessuno dei tag `h3`, `h2`, o `h1`, cerca un tag `p`:\n",
        "\n",
        "All'interno del tag `p`, rimuove eventuali tag `strong`.\n",
        "Trasforma il `p` in `h1`, rimuove eventuali tag `span` contenuti al suo interno e estrae il testo.\n",
        "Se riesce a estrarre del testo, lo aggiunge al tag `title`.\n",
        "\n",
        "Se il curatore è uno tra Caterina Iagnemma, Sofia Confalonieri o Maurizio Cau, prende semplicemente il testo dal tag `h1` e lo aggiunge al tag `title`.\n",
        "\n",
        "Infine, inserisce il tag `title` creato all'inizio del documento HTML, all'interno del tag `head`."
      ],
      "metadata": {
        "id": "S8Te6gLUWiYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# REMOVE TRASH AND SCRAPS TAGS\n",
        "def clean_trash_and_scraps(soup):\n",
        "    try:\n",
        "        trash_entities = soup.find_all(attrs={'typeof': 'moro:Trash'}) #find the attribute typeof with moro:Trash or moro:Scraps\n",
        "        scraps_entities = soup.find_all(attrs={'typeof': 'moro:Scraps'})\n",
        "        total = trash_entities + scraps_entities #add the two lists together\n",
        "        if len(total) > 0: #if the list is not empty\n",
        "            for el in total: #iterate through the list\n",
        "                mentions = soup.find_all(attrs={'resource': el['about']})\n",
        "                metas = soup.find_all('meta', attrs={'about': el['about']})\n",
        "                for meta in metas:\n",
        "                    meta.decompose()\n",
        "                for mention in mentions:\n",
        "                    mention.unwrap()\n",
        "    except: None"
      ],
      "metadata": {
        "id": "kSo8qReKaCNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "La funzione `clean_trash_and_scraps` rimuove tag non desiderati dal documento HTML.\n"
      ],
      "metadata": {
        "id": "rXzjwY9KaNiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FIX CURATOR NOTES AND REMOVE TAGS INSIDE THEM\n",
        "def clean_curator_notes(soup, spans, dataset_ns, metadata):\n",
        "    notes_section = soup.find('ol', id='curatorNotes') #find the curator notes\n",
        "    if notes_section:\n",
        "        notes = notes_section.find_all(attrs={'typeof': 'moro:Footnote'})\n",
        "        if notes: #if the list of notes is not empty\n",
        "            for note in notes:\n",
        "                note['about'] = dataset_ns + f'{metadata[\"ident\"].replace(\"_\", \"\")}/v1/' + note['about'][1:] #add the dataset namespace to the about attribute of the note\n",
        "                note['typeof'] = 'fabio:Comment' #set the typeof attribute of the note to fabio:Comment\n",
        "                h3 = note.find('h3') #find the h3 tag inside the note and remove them\n",
        "                if h3:\n",
        "                    h3.unwrap()\n",
        "                ps = note.find_all('p') #find all p tags inside the note and remove them\n",
        "                if ps:\n",
        "                    for p in ps:\n",
        "                        for span in spans:\n",
        "                            if span in p.find_all('span') and 'bibref' not in span['class']: #if the span is inside p and has no class bibref\n",
        "                                span.unwrap() #remove the span from the document\n",
        "                        p.unwrap() #remove the p tag from the document"
      ],
      "metadata": {
        "id": "LS7cZAPkvtdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "La funzione `clean_curator_notes` pulisce e modifica le note del curatore nel documento HTML, rimuovendo tag non necessari e aggiornando gli attributi."
      ],
      "metadata": {
        "id": "ORhimz4ov4Yr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FIX MORO NOTES AND REMOVE TAGS INSIDE THEM\n",
        "def clean_moro_notes(soup, spans, dataset_ns, metadata):\n",
        "    notes_section = soup.find('ol', id='moroNotes')\n",
        "    if notes_section:\n",
        "        notes = notes_section.find_all('li')\n",
        "        if notes:\n",
        "            for note in notes:\n",
        "                note['about'] = dataset_ns + f'{metadata[\"ident\"].replace(\"_\", \"\")}/v1/' + note['about'][1:]\n",
        "                note['typeof'] = 'fabio:Comment'\n",
        "                del note['data-toggle']\n",
        "                del note['data-placement']\n",
        "                del note['title']\n",
        "                del note['data-original-title']\n",
        "                del note['class']\n",
        "                ps = note.find_all('p')\n",
        "                if ps:\n",
        "                    for p in ps:\n",
        "                        for span in spans:\n",
        "                            if span in p.find_all('span') and 'bibref' not in span['class']:\n",
        "                                span.unwrap()\n",
        "                        p.unwrap()\n",
        "\n",
        "                for child in note.children:\n",
        "                    if child.string:\n",
        "                        fixed_text = child.string.replace('[', '').replace(']', '')\n",
        "                        child.string.replace_with(fixed_text)\n",
        "\n",
        "        del notes_section['data-alert']"
      ],
      "metadata": {
        "id": "lvLHXmpyv8er"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}